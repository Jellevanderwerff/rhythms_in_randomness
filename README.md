# Humans can find rhythm in randomly timed sounds

This repository contains the data, analysis code, and supplementary materials for the article **"Humans can find rhythm in randomly timed sounds"**.

## Abstract

To be added.

## Contents

```
.
├── data
│   ├── modelled
│   ├── musical_experience
│   ├── simulated
│   ├── tapping_clean
│   ├── tapping_discarded
│   └── tapping_raw
│       ├── data_participants_info
│       └── data_participants_tapping
├── figures
├── notes
├── plots
│   ├── modelled
│   ├── simulated
│   └── tapping
│       └── assumptions
└── scripts
    ├── modelled
    ├── simulated
    │   ├── autocorrelations
    │   ├── iois_distributions
    │   └── prepare_dataframes
    └── tapping
        ├── asynchronies
        ├── autocorrelations
        ├── checks
        ├── continuation
        ├── missing_data
        ├── musical_experience
        ├── prepare_dataframes
        ├── tempo
        └── variability
```

## Citation

If you use this code or data, please cite our article:

> Jelle van der Werff, Tommaso Tufarelli, Laura Verga, Andrea Ravignani (2025). Humans can find rhythm in randomly timed sounds.

## Contact

For questions or feedback, please contact the article's corresponding authors.